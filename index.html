<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Experiment summary</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-905433ffa22618bb005779f2b23c5ce0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="floating quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a>
  <ul class="collapse">
  <li><a href="#session-types" id="toc-session-types" class="nav-link" data-scroll-target="#session-types">Session Types</a>
  <ul class="collapse">
  <li><a href="#of1-and-of2" id="toc-of1-and-of2" class="nav-link" data-scroll-target="#of1-and-of2">OF1 and OF2</a></li>
  <li><a href="#vr" id="toc-vr" class="nav-link" data-scroll-target="#vr">VR</a></li>
  <li><a href="#vrmc" id="toc-vrmc" class="nav-link" data-scroll-target="#vrmc">VRMC</a></li>
  <li><a href="#imseq" id="toc-imseq" class="nav-link" data-scroll-target="#imseq">IMSEQ</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a>
  <ul class="collapse">
  <li><a href="#data-overview" id="toc-data-overview" class="nav-link" data-scroll-target="#data-overview">Data overview</a></li>
  <li><a href="#accessing-raw-data" id="toc-accessing-raw-data" class="nav-link" data-scroll-target="#accessing-raw-data">Accessing raw data</a>
  <ul class="collapse">
  <li><a href="#folder-structure" id="toc-folder-structure" class="nav-link" data-scroll-target="#folder-structure">Folder structure</a></li>
  <li><a href="#raw-ephys-recordings" id="toc-raw-ephys-recordings" class="nav-link" data-scroll-target="#raw-ephys-recordings">Raw Ephys recordings</a></li>
  <li><a href="#video-files" id="toc-video-files" class="nav-link" data-scroll-target="#video-files">Video files</a></li>
  </ul></li>
  <li><a href="#accessing-derived-data" id="toc-accessing-derived-data" class="nav-link" data-scroll-target="#accessing-derived-data">Accessing Derived data</a>
  <ul class="collapse">
  <li><a href="#folder-structure-1" id="toc-folder-structure-1" class="nav-link" data-scroll-target="#folder-structure-1">Folder structure</a></li>
  <li><a href="#spike-data" id="toc-spike-data" class="nav-link" data-scroll-target="#spike-data">Spike data</a></li>
  <li><a href="#behavioural-data" id="toc-behavioural-data" class="nav-link" data-scroll-target="#behavioural-data">Behavioural Data</a></li>
  <li><a href="#sortinganalyzer" id="toc-sortinganalyzer" class="nav-link" data-scroll-target="#sortinganalyzer">SortingAnalyzer</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#technical-details" id="toc-technical-details" class="nav-link" data-scroll-target="#technical-details">Technical details</a>
  <ul class="collapse">
  <li><a href="#code-protocols" id="toc-code-protocols" class="nav-link" data-scroll-target="#code-protocols">Code Protocols</a></li>
  <li><a href="#experimental-protocols" id="toc-experimental-protocols" class="nav-link" data-scroll-target="#experimental-protocols">Experimental Protocols</a></li>
  <li><a href="#feature-extraction-from-video-data" id="toc-feature-extraction-from-video-data" class="nav-link" data-scroll-target="#feature-extraction-from-video-data">Feature Extraction from video data</a></li>
  </ul></li>
  <li><a href="#experimental-details" id="toc-experimental-details" class="nav-link" data-scroll-target="#experimental-details">Experimental details</a>
  <ul class="collapse">
  <li><a href="#faq" id="toc-faq" class="nav-link" data-scroll-target="#faq">FAQ</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Experiment summary</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="overview" class="level1">
<h1>Overview</h1>
<p>This experiment is designed to find out stuff about memory.</p>
<section id="session-types" class="level2">
<h2 class="anchored" data-anchor-id="session-types">Session Types</h2>
<p>Each day, each mouse participated in one or more sessions. E.g. in the most common day, a mouse partakes in an open field session, then a virtual reality session, then a second open field session. Our data is organised around these sessions, so it is helpful to understand them to understand the data. The session types are</p>
<section id="of1-and-of2" class="level3">
<h3 class="anchored" data-anchor-id="of1-and-of2">OF1 and OF2</h3>
<p>An open field session. The mouse is placed in a 1m by 1m arena.</p>
</section>
<section id="vr" class="level3">
<h3 class="anchored" data-anchor-id="vr">VR</h3>
<p>A virtual reality session. The mouse is head-fixed, on a wheel in a virtual reality system. The plain <code>VR</code> tag is used for the simplest of our VR tasks, described in … .</p>
</section>
<section id="vrmc" class="level3">
<h3 class="anchored" data-anchor-id="vrmc">VRMC</h3>
<p>A virtual reality multi context session. The mouse is head-fixed, on a wheel in a virtual reality system. The reward zone, described above, is in one of two locations in each trail. The mouse is alerted of this change through the walls changing colour.</p>
</section>
<section id="imseq" class="level3">
<h3 class="anchored" data-anchor-id="imseq">IMSEQ</h3>
<p>Image sequence stuff…</p>
</section>
</section>
</section>
<section id="data" class="level1">
<h1>Data</h1>
<section id="data-overview" class="level2">
<h2 class="anchored" data-anchor-id="data-overview">Data overview</h2>
<p>Our basic pipeline overview can be found below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://raw.githubusercontent.com/chrishalcrow/harry_data_readme/refs/heads/main/images/pipelineoverview.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Pipeline overview"><img src="https://raw.githubusercontent.com/chrishalcrow/harry_data_readme/refs/heads/main/images/pipelineoverview.png" class="img-fluid figure-img" alt="Pipeline overview"></a></p>
<figcaption>Pipeline overview</figcaption>
</figure>
</div>
<p>Every session contains an output from Bonsai or Blender, and a Video. These capture the animal behaviour data, as well as a light pulse signal used for synchronisation. Most sessions include ephys data, which capture neural behaviour.</p>
<p>We expect the most useful data to be the <code>outputs for analysis</code> (in teal), or the <code>raw data</code> (in red) or the . Find out how to access the <a href="#accessing-raw-data">Raw data</a> and <a href="#accessing-derived-data">Derived data</a> below. We explain how each script was implemented in the <a href="#code-protocols">Code Protocols</a> section.</p>
</section>
<section id="accessing-raw-data" class="level2">
<h2 class="anchored" data-anchor-id="accessing-raw-data">Accessing raw data</h2>
<section id="folder-structure" class="level3">
<h3 class="anchored" data-anchor-id="folder-structure">Folder structure</h3>
<p>The raw data is organised as follows:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>data_folder<span class="op">/</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    session_folder<span class="op">/</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        M{mouse}_D{day}_datetime_{session_abbreviation}<span class="op">/</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>            params.yaml  <span class="co"># metadata about the experiment</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>            {video_file}.avi  <span class="co"># video of behaviour</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>            {behaviour_files}.csv  <span class="co"># behavioural output from Bonsai/Blender</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>            Record Node <span class="dv">102</span><span class="op">/</span>  <span class="co"># Ephys data</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>                experiment1<span class="op">/</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                    recording1<span class="op">/</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                        continous<span class="op">/</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                        events<span class="op">/</span> (<span class="kw">not</span> used)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                        spikes<span class="op">/</span> (<span class="kw">not</span> used)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                        structure.oebin</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>            </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>where datetime is the time the session began.</p>
<p>For example, the VR data for mouse 25, day 20 in stored in</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">"data_folder/vr/M25_D20_2024-11-08_11-52-50_VR1"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Find out more about the data below.</p>
</section>
<section id="raw-ephys-recordings" class="level3">
<h3 class="anchored" data-anchor-id="raw-ephys-recordings">Raw Ephys recordings</h3>
<p>Stored at</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>data_folder<span class="op">/</span>Cohort_folder<span class="op">/</span>session_folder<span class="op">/</span>M1_D1_datetime_{session}<span class="op">/</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Openphys files. Roughly a large binary file with some metadata.</p>
<p>These can be read using <code>spikeinterface</code> e.g.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spikeinterface.full <span class="im">as</span> si</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>path_to_recording <span class="op">=</span> <span class="st">"data_folder/of/M25_D20_2024-11-08_11-25-37_OF1/"</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>recording <span class="op">=</span> si.read_openephys(path_to_recording)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="video-files" class="level3">
<h3 class="anchored" data-anchor-id="video-files">Video files</h3>
<p>Stored at</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>data_folder<span class="op">/</span>Cohort_folder<span class="op">/</span>session_folder<span class="op">/</span>M1_D1_datetime_{session}<span class="op">/</span>{video_name}.avi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Videos are named using the BIDS structure, meaning they are of the form <code>sub-{mouse}_day-{day}_ses-{session}_video.avi</code>, e.g.&nbsp;<code>sub-20_day-25_ses-OF1_video.avi</code>.</p>
<p><strong>Open Field</strong> gives a top-down view of the open field arena. Used to determine mouse position. Frame rate is 15 frames per second.</p>
<p><strong>VR</strong> gives side view of mouse while running. Used to determine Tongue position and pupil dilation. Frame rate is 30 frames per second.</p>
</section>
</section>
<section id="accessing-derived-data" class="level2">
<h2 class="anchored" data-anchor-id="accessing-derived-data">Accessing Derived data</h2>
<p>Most of the derived data is in <code>NOLANLABDATASTORE/ActiveProjects/Wolf/COHORT12/</code>. The Sorting Analyzer are kept in <code>NOLANLABDATASTORE/ActiveProjects/Chris/Cohort12/derivatives</code>.</p>
<p>All of this data is synchronized.</p>
<section id="folder-structure-1" class="level3">
<h3 class="anchored" data-anchor-id="folder-structure-1">Folder structure</h3>
<p>Each mouse day (usually) corresponds to one “experiment”, which might contain several “sessions”. To reflect this, the derived data is organised as follows:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>derivatives_folder<span class="op">/</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    M{mouse}<span class="op">/</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        D{day}<span class="op">/</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>            full<span class="op">/</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>            {session_type_1}<span class="op">/</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>            {session_type_2}<span class="op">/</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>            ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The information in <code>full</code> is shared between all sessions in the experiment (e.g.&nbsp;if all the data is sorted together, the sorted data is stored here) while information unique to each session is stored in the <code>session_type_n</code> folder. This folder can contain <em>many</em> pieces of data. The data is described below.</p>
</section>
<section id="spike-data" class="level3">
<h3 class="anchored" data-anchor-id="spike-data">Spike data</h3>
<p>Stored at</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">/</span>ActiveProjects<span class="op">/</span>Wolf<span class="op">/</span>COHORT12<span class="op">/</span>M{mouse}<span class="op">/</span>D{day}<span class="op">/</span>{session}<span class="op">/</span>sub<span class="op">-</span>{mouse}_day<span class="op">-</span>{day}_ses<span class="op">-</span>{session}_srt<span class="op">-</span>{sorter_protocol}_clusters.npz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Contains sorted (but non-curated) clusters. Most importantly each cluster contains a spike train, giving timepoints for each spike in that cluster in seconds. The file is an <code>npz</code> file which can be read using <code>numpy</code>. However, we recommend using <code>pyanpple</code> to open them. The following code snippets loads a file and bins its spike train:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pynapple <span class="im">as</span> nap</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>mouse <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>day <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>session <span class="op">=</span> <span class="st">"OF1"</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>srt <span class="op">=</span> <span class="st">"kilosort4"</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>path_to_active_project <span class="op">=</span> Path(<span class="st">"/Volumes/cmvm/sbms/groups/CDBS_SIDB_storage/NolanLab/ActiveProjects/"</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>session_folder <span class="op">=</span> path_to_active_project <span class="op">/</span> <span class="ss">f"Wolf/COHORT12/M</span><span class="sc">{</span>mouse<span class="sc">}</span><span class="ss">/D</span><span class="sc">{</span>day<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>session<span class="sc">}</span><span class="ss">/"</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>clusters_file <span class="op">=</span> session_folder <span class="op">/</span> <span class="ss">f"sub-</span><span class="sc">{</span>mouse<span class="sc">}</span><span class="ss">_day-</span><span class="sc">{</span>day<span class="sc">}</span><span class="ss">_ses-</span><span class="sc">{</span>session<span class="sc">}</span><span class="ss">_srt-</span><span class="sc">{</span>srt<span class="sc">}</span><span class="ss">_clusters.npz"</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> nap.load_file(clusters_file)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># print the time stamps of cluster 19</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(clusters[<span class="dv">19</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We also store metadata. All the metadata can be accessed through <code>clusters.metadata</code>. This includes:</p>
<p>Quality metrics of each cluster, taken from the <code>SortingAnalyzer</code>, which can be used to curate:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find all clusters with a firing rate greater than 10, then subselect using these</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>high_firing_clusters <span class="op">=</span> clusters[clusters[<span class="st">'firing_rate'</span>] <span class="op">&gt;</span> <span class="dv">10</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print how many clusters there are with a high firing rate</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(high_firing_clusters))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Anatomical information for each cluster. This is the estimate position of the cluster in the brain. We can access the stereotaxic coordinds, common coordinate framework or the estimated brain region as follows:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print the brain region of cluster 6:</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>clusters[<span class="st">'brain_region'</span>][<span class="dv">6</span>]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># print the CCF coords of cluster 12:</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>CCFs <span class="op">=</span> clusters[[<span class="st">'coord_CCFs_z'</span>, <span class="st">'coord_CCFs_y'</span>, <span class="st">'coord_CCFs_x'</span>]]</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(CCFs.iloc[<span class="dv">12</span>])</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># print the SC coords of cluster 16:</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>SCs <span class="op">=</span> clusters[[<span class="st">'coord_SCs_x'</span>,<span class="st">'coord_SCs_y'</span>,<span class="st">'coord_SCs_z'</span>]]</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SCs.iloc[<span class="dv">16</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="behavioural-data" class="level3">
<h3 class="anchored" data-anchor-id="behavioural-data">Behavioural Data</h3>
<p>Stored at</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="op">/</span>ActiveProjects<span class="op">/</span>Wolf<span class="op">/</span>COHORT12<span class="op">/</span>M{mouse}<span class="op">/</span>D{day}<span class="op">/</span>{session}<span class="op">/</span>sub<span class="op">-</span>{mouse}_day<span class="op">-</span>{day}_ses<span class="op">-</span>{session}_srt<span class="op">-</span>{sorter_protocol}_beh.nwb</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>These are <code>NeurodataWithoutBorder</code> files. Can be read with the <code>pynwb</code> or <code>matnwb</code> packages, but we recommend using <code>pynapple</code>. The behavioural data stored depends on the session</p>
<p>Regardless of session type, they are loaded the same way, and we can investigate what is saved in them as follow:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pynapple <span class="im">as</span> nap</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>mouse <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>day <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>session <span class="op">=</span> <span class="st">"OF1"</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>path_to_active_project <span class="op">=</span> Path(<span class="st">"/Volumes/cmvm/sbms/groups/CDBS_SIDB_storage/NolanLab/ActiveProjects/"</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>session_folder <span class="op">=</span> path_to_active_project <span class="op">/</span> <span class="ss">f"Wolf/COHORT12/M</span><span class="sc">{</span>mouse<span class="sc">}</span><span class="ss">/D</span><span class="sc">{</span>day<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>session<span class="sc">}</span><span class="ss">/"</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>beh_file <span class="op">=</span> session_folder <span class="op">/</span> <span class="ss">f"sub-</span><span class="sc">{</span>mouse<span class="sc">}</span><span class="ss">_day-</span><span class="sc">{</span>day<span class="sc">}</span><span class="ss">_ses-</span><span class="sc">{</span>session<span class="sc">}</span><span class="ss">_beh.nwb"</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>beh <span class="op">=</span> nap.load_file(beh_file)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co"># see what is saved</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(beh)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We’ll discuss the most important data that we save below:</p>
<section id="of-behavioural-data" class="level4">
<h4 class="anchored" data-anchor-id="of-behavioural-data">OF behavioural data</h4>
<ul>
<li><strong>P_x</strong> and <strong>P_y</strong>. Time series of position in cartesian coordinates, in units of cm.</li>
<li><strong>S</strong>. Time series of computed speed of mouse, in cm/s.</li>
<li><strong>moving</strong>. Interval set of whether or not the mouse is moving, with threshold ?? (WOLF).</li>
</ul>
</section>
<section id="vr-behavioural-data" class="level4">
<h4 class="anchored" data-anchor-id="vr-behavioural-data">VR behavioural data</h4>
<ul>
<li><strong>P</strong>. Time series of position along the VR track, in units of cm.</li>
<li><strong>S</strong>. Time series of computed speed along the VR track, in units of cm.</li>
<li><strong>moving</strong>. Interval set of whether of not the mouse is moving.</li>
<li><strong>lick</strong>. Time series of when the mouse licks.</li>
<li><strong>eye_dilation</strong>. Time series of pupil dilation, in dimensionless units.</li>
<li><strong>trials</strong>. Interval set of trails. Used to pick out individual trails.</li>
<li><strong>trial_type</strong>. Time series of which trial type is active at any time point. Type 0 is uncued and type 1 is cued.</li>
</ul>
</section>
<section id="example-code" class="level4">
<h4 class="anchored" data-anchor-id="example-code">Example code</h4>
<p>We use <code>pynapple</code> to combine behavioral and spiking data. For example, to compute the most basic positional turning curve in VR we can run</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>beh <span class="op">=</span> nap.load_file(beh_file)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> nap.load_file(clusters_file)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>positional_tuning_curves <span class="op">=</span> nap.compute_1d_tuning_curves(</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    group<span class="op">=</span>clusters,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    feature<span class="op">=</span>beh[<span class="st">'P'</span>],</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    nb_bins<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>which we can plot…</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>cluster_id <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>ax.plot(positional_tuning_curves[cluster_id])</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Position along track"</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Firing rate (Hz)"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">"positional_tuning_curve_cluster_</span><span class="sc">{cluster_id}</span><span class="st">.pdf"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The real power of <code>pynapple</code> is dealing with time sub-selection using the <code>epoch</code> concept (<a href="https://pynapple.org/user_guide/01_introduction_to_pynapple.html#">read more</a>).</p>
<p>In the following code we compute a 1D tuning curve only when the mouse is moving and only during cued trails:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>beaconed_trials <span class="op">=</span> beh[<span class="st">'trials'</span>][beh[<span class="st">'trials'</span>][<span class="st">'type'</span>] <span class="op">==</span> <span class="st">'b'</span>]</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>moving_and_beaconed <span class="op">=</span> beh[<span class="st">'moving'</span>].intersect(beaconed_trials)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>positional_tuning_curves <span class="op">=</span> nap.compute_1d_tuning_curves(</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    group<span class="op">=</span>clusters,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    feature<span class="op">=</span>beh[<span class="st">'P'</span>],</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    nb_bins<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    ep<span class="op">=</span>moving_and_beaconed,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="sortinganalyzer" class="level3">
<h3 class="anchored" data-anchor-id="sortinganalyzer">SortingAnalyzer</h3>
<p>Stored at</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="op">/</span>ActiveProjects<span class="op">/</span>Chris<span class="op">/</span>Cohort12<span class="op">/</span>derivatives</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A <code>spikeinterface</code> <code>SortingAnalyzer</code> object, containing spike times and dervied information such as unit templates, spike locations etc. The analyzer depends on the sorter used. We label each sorting protocol by a number. The details of the protocols can be found in the <a href="#protocols">Protocols</a> section.</p>
<p>Can be read using <code>spikeinterface</code></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spikeinterface.full <span class="im">as</span> si</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>sa_path <span class="op">=</span> <span class="st">"derivatives/M25/D20/full/kilosort4/kilosort4_sa"</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>sorting_analyzer <span class="op">=</span> si.read_sorting_analyzer(sa_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Used for more intricate curation and for comparisons of different spike sorters. Our default sorting is the protocol <code>kilosort4</code>.</p>
<p>Read more about <code>SortingAnalyzer</code>s <a href="https://spikeinterface.readthedocs.io/en/stable/modules/postprocessing.html">here</a>, <a href="https://spikeinterface.readthedocs.io/en/stable/tutorials/core/plot_4_sorting_analyzer.html#sphx-glr-tutorials-core-plot-4-sorting-analyzer-py">here</a> and <a href="https://youtu.be/pHze_8s4Qak?feature=shared&amp;t=3590">here (video)</a>.</p>
</section>
</section>
</section>
<section id="technical-details" class="level1">
<h1>Technical details</h1>
<section id="code-protocols" class="level2">
<h2 class="anchored" data-anchor-id="code-protocols">Code Protocols</h2>
<p>Hello!</p>
</section>
<section id="experimental-protocols" class="level2">
<h2 class="anchored" data-anchor-id="experimental-protocols">Experimental Protocols</h2>
<p>add links to nolanlab wiki for surgery protocol for neuropixel implantation add links to nolanlab wiki for experimental protocol including behaviour, water dep etc add links to nolanlab wiki for extracting coordniates from DiI tracks using Probe-TRACK and custom scripts add links to nolanlab wiki for extracting features from video including licks, pupil dilation, steps and pose anything else?</p>
</section>
<section id="feature-extraction-from-video-data" class="level2">
<h2 class="anchored" data-anchor-id="feature-extraction-from-video-data">Feature Extraction from video data</h2>
<p>How do we extract behavioural variables from video footage? Deeplabcut! We manually labelled the pixel location for features of interest from raw video data. We then trained bespoke deeplabcut models to infer pixel positions for each video in the dataset.</p>
<p>Open field videos captured the mouse’s movement in the square arena with a birds eye view. We estimated the mouse’s pose using five features including head, shoulders, middle, tail start and tail end. Pixel coordinates coordinates were transformed and scaled to match the 1 m x 1 m dimensions of the open arena. To estimate head direction, we took the vector between the head and middle features and calculated an angle relative to north.</p>
<p>Add image or gif?</p>
<p>Virtual reality videos captured a side view of the mouse while head-restraint on a cylindrical treadmill. We estimated the mouse’s pupil diameter using eight features including eye north, eye north-east, eye-east etc. Pupil diamter was defined as the average pixel distance between opposite features such as north vs south, north-east vs south-west etc. Units for pupil diameter are arbitrarily defined as we were only concerned with relative changes.</p>
<p>add image or gif of pupil models</p>
<p>We estimated when the mouse’s was engaged in licking using a single feature marking the position of the tongue. When the tongue was out of sight (in the mouse’s mouth), we marked the tongue’s position as the bottom of the mouth. Plotting the tongues position across a session typically produced a point cloud with two clearly defined clusters. To label positions attributable to lick events, we manually drew around the lower positioned cluster. Finally we visually verified this method by creating gif snippets for each session and accessing whether licks were labelled accurately.</p>
<p><a href="https://raw.githubusercontent.com/chrishalcrow/harry_data_readme/refs/heads/main/images/M20_D23_vr_dlc_tongue_points.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Tongue position feature extraction"><img src="https://raw.githubusercontent.com/chrishalcrow/harry_data_readme/refs/heads/main/images/M20_D23_vr_dlc_tongue_points.png" class="img-fluid" alt="Tongue position feature extraction"></a> <a href="https://raw.githubusercontent.com/chrishalcrow/harry_data_readme/refs/heads/main/images/M20_D23_vr_dlc_tongue_points_classified.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Drawing around lick point cloud"><img src="https://raw.githubusercontent.com/chrishalcrow/harry_data_readme/refs/heads/main/images/M20_D23_vr_dlc_tongue_points_classified.png" class="img-fluid" alt="Drawing around lick point cloud"></a> <a href="https://raw.githubusercontent.com/chrishalcrow/harry_data_readme/refs/heads/main/images/M20_D23_vr_2.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Lick frames"><img src="https://raw.githubusercontent.com/chrishalcrow/harry_data_readme/refs/heads/main/images/M20_D23_vr_2.gif" class="img-fluid" alt="Lick frames"></a></p>
<p>add image or gif of lick models</p>
</section>
</section>
<section id="experimental-details" class="level1">
<h1>Experimental details</h1>
<p>We stereotaxically targeted the medial entorhinal cortex of 7 males and 1 female C57BL/6J mice with Neuropixel 2.0 (NP2; 4 shank) probes. Prior to implantation of the NP2 probes, mice were trained in the VR linear track experiment to an expert level in both beaconed and non-beaconed trial variants (see Tennant et al., 2018; 10.1016/j.celrep.2018.01.005).</p>
<p>Changes to the task from Tennant et al., 2018, Tennant et al., 2022 and Clark and Nolan, 2024 (T18, T22 and C24 respectively):</p>
<ul>
<li>Water deprivation was used instead of food deprivation therefore 10% sucrose solution was used as reward instead of soy milk. The volume of sucrose solution varied between 5-10 uL per reward dispensed.</li>
<li>A speed of 3 cm/s was used as the stop threshold, compared to 0.7 cm/s and 4.7 cm/s used in T18 and T22.</li>
<li>Probe trials (non-beaconed trials without reward) were not recorded in this experiment.</li>
<li>Upon teleportation back to the start of the track, trial type was randomised with equal weighting to beaconed and non-beaconed trials, this produced an equal number of beaconed and non-beaconed trials compared to the repeated block structures used in T18 and T22.</li>
<li>Mice were only implanted once they reached an expert level in the task.</li>
<li>Electrophysiology was acquired using a National Instruments/IMEC acquisition system and recorded using Open Ephys software using the Neuropixel acquisition external plugin.</li>
<li>Behavioural variables were stored and saved directly from Blender3D, and time synced retrospectively using aperiodic TTL pulses sent directly to both the Neuropixel acquisition system and Blender3D via a custom Arduino Due.</li>
</ul>
<section id="faq" class="level2">
<h2 class="anchored" data-anchor-id="faq">FAQ</h2>
<p><strong>How was the experiment conducted on a typical day?</strong></p>
<p>Experimental days involved recording from mice in the open arena and then in the virtual location memory task and then once again in the open arena. Mice were collected from the holding room 30 - 60 minutes before recording, were handled for 5 - 10 minutes, weighed and placed for 10 - 20 minutes in a cage containing objects and a running wheel. Between recording sessions mice were placed back in the object-filled playground for 10 - 20 minutes. The open arena consisted of a metal box with a square floor area, removable metal walls, metal frame (Frame parts from Kanya UK, C01-1, C20-10, A33-12, B49-75, B48-75, A39-31, ALU3), and an A4-sized cue card in the middle of one of the metal walls. For the open field exploration session, mice were placed in the open arena while tethered via an ultrathin Neuropixel aquisition cable No Commutator was used. In a small number of sessions, tangling of the Neuropixel cable caused the cable to fall in front of the mouse. To stop mice from knawing on the cable, Mice were quickly untangled by the experimentor. For the location memory task water-restricted mice were trained to obtain rewards at a location on the virtual linear track. Mice were head-fixed using a RIVETS clamp (Ronal Tool Company, Inc) and ran on a cylindrical treadmill fitted with a rotary encoder (Pewatron). Virtual tracks, generated using Blender3D (blender.com) had length 200 cm, with a 60 cm track zone, a 20 cm reward zone, a second 60 cm track zone and a 60 cm black box to separate successive trials. The distance visible ahead of the mouse was 50 cm. The reward zone was either marked by distinct vertical green and black bars on beaconed trials, or was not marked by a visual cue at all on non-beaconed. A feeding tube placed in front of the animal dispensed 10 % sucrose water rewards (5 - 10 5l per reward) if the mouse stopped in the reward zone. A stop was registered in Blender3D if the speed of the mouse dropped below 3 cm/s. Speed was calculated on a rolling basis from the previous 100 ms at a rate of 60 Hz. Trials were delivered in a random fashion with a equal probability on any given trial of being beaconed or non-beaconed. Mice were trained to an expert level in the location memory task before being implanted with Neuropixel 2.0 probes and undergoing the three session (open arena/location memory task/open arena) For more details, see Clark and Nolan 2024, https://doi.org/10.7554/eLife.89356.2</p>
<p><strong>How was data collected?</strong></p>
<p>Electrophysiological signals were acquired using a Neuropixel 2.0 headstage connected via an Neuropixel aquisition cable attached to an IMEC-National Instruments aquisition system (recommended hardware as of July 2024). For the location memory task, positional and trial information was saved in Blender3D at 60 Hz and time sync with TTL pulses delivered concurrently to the Neuropixel aquisition system and the Blender3D computer via an arduino Due. In the open arena, motion and head-direction tracking used a camera (Logitech B525, 1280 x 720 pixels Webcam, RS components 795-0876) attached to the celing of the frame. A custom bonsai tracking script picked up the TTL pulses delivered to an LED in sight of the tracking camera and out of sight of the freely exploring mouse. Body and head direction tracking was completed post-recording using DeepLabCut.</p>
<p><strong>What was the surgery schedule of the experiment?</strong></p>
<p>Mice underwent two seperate surgeries under anaesthesia, the first being a headpost attachment surgery followed by a Neuropixel 2.0 implantation mounted on a Apollo drive resuable 3D printed body. All surgeries were performed by Harry Clark</p>
<p><strong>What drugs were used in the experiment?</strong></p>
<p>Isoflurane used during surgery. Vetergesic jelly given post surgery. Carprofen and Buprenorphine were given subcutaneously at the recommended dosage post surgery</p>
<p><strong>How can I reproduce the stereotaxic surgery?</strong></p>
<p>Add this</p>
<p><strong>Where can I find files for 3D printing the reusable 3D printed components?</strong></p>
<p>Add this Include rivets custom designs</p>
<p><strong>Where can I find the used NP2 probes for use in future experiments?</strong></p>
<p>There are currently 4 x NP2 4-shank probes ready to be used for implantation. These can be found within the 2nd floor wet lab room (add room number) in the drive building area. A box labelled with “Neuropixel 2.0 4 shank probes, Harry Clark” can be found on the shelf above the drive building bench in the drive staging area (marked by yellow tape). (This information was accurate as of 04/03/2025). These drives are super-glued to an Apollo drive shuttle and thus can only be used for further experimentation with Apollo drive compatible components.</p>
<p><strong>Still missing a vital piece of information?</strong></p>
<p>Email harrydclark91@gmail.com for further clarification so we can add the relevant information to this document.</p>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<p>Tennant et al., 2018; 10.1016/j.celrep.2018.01.005 Tennant et al., 2022; 10.1016/j.cub.2022.08.050 Clark and Nolan, 2024; 10.7554/eLife.89356.3</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/chrishalcrow\.github\.io\/harry_data_readme\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>